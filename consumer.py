#!/usr/bin/env python3
"""
Consumer para el ejercicio de las 4 Vs del Big Data
Lee y procesa datos mostrando tiempos de ejecuci√≥n
"""

import argparse
import time
import json
import csv
import glob
from pathlib import Path
from collections import defaultdict
try:
    import matplotlib
    matplotlib.use('Agg')  # Backend sin GUI para generar archivos
    import matplotlib.pyplot as plt
    import numpy as np
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    print("‚ö†Ô∏è  matplotlib no est√° disponible. Las gr√°ficas no se generar√°n.")
    print("   Instala con: pip install matplotlib seaborn numpy")

class BigDataConsumer:
    def __init__(self, velocity=False, volume=False, variety=False, veracity=False):
        self.velocity = velocity
        self.volume = volume
        self.variety = variety
        self.veracity = veracity
        self.data_folder = Path("data")
        self.output_folder = "."  # Carpeta donde se guardan las gr√°ficas (directorio actual)
        
        # Contador para mostrar solo cuando hay cambios significativos
        self.last_file_sizes = {}
        
        # Para velocity: trackear cu√°ntos n√∫meros ya hemos procesado
        self.processed_count = 0
        
        # Para generar gr√°ficas: recopilar datos de rendimiento
        self.performance_data = {
            'iterations': [],
            'processing_times': [],
            'numbers_in_file': [],
            'numbers_processed': [],
            'total_numbers_processed': [],
            'veracity_errors': []
        }

    def read_txt_file(self, filepath):
        """Lee n√∫meros de un archivo TXT"""
        numbers = []
        try:
            with open(filepath, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        numbers.append(int(line))
        except (ValueError, FileNotFoundError):
            pass
        return numbers

    def read_csv_file(self, filepath):
        """Lee n√∫meros de un archivo CSV"""
        numbers = []
        try:
            with open(filepath, 'r') as f:
                reader = csv.reader(f)
                next(reader, None)  # Skip header
                for row in reader:
                    if row:
                        numbers.append(int(row[0]))
        except (ValueError, FileNotFoundError, IndexError):
            pass
        return numbers

    def read_json_file(self, filepath):
        """Lee n√∫meros de un archivo JSON"""
        numbers = []
        try:
            with open(filepath, 'r') as f:
                data = json.load(f)
                if 'numbers' in data:
                    numbers = data['numbers']
        except (json.JSONDecodeError, FileNotFoundError, KeyError):
            pass
        return numbers

    def get_file_numbers(self, filepath):
        """Obtiene n√∫meros de un archivo seg√∫n su extensi√≥n"""
        path = Path(filepath)
        
        if path.suffix == '.txt':
            return self.read_txt_file(filepath)
        elif path.suffix == '.csv':
            return self.read_csv_file(filepath)
        elif path.suffix == '.json':
            return self.read_json_file(filepath)
        
        return []

    def get_next_number_for_velocity(self, filepath):
        """Para velocity: obtiene solo el siguiente n√∫mero no procesado"""
        numbers = self.get_file_numbers(filepath)
        
        # Si hay n√∫meros nuevos m√°s all√° de los ya procesados
        if len(numbers) > self.processed_count:
            # Devolver solo el siguiente n√∫mero
            next_number = numbers[self.processed_count]
            self.processed_count += 1
            return [next_number], len(numbers)  # [n√∫mero], total_en_archivo
        
        return [], len(numbers)  # Sin n√∫meros nuevos

    def _generate_chart_filename(self):
        """Genera el nombre del archivo basado en las V's activadas"""
        v_names = []
        if self.velocity: v_names.append('vel')
        if self.volume: v_names.append('vol')
        if self.variety: v_names.append('var')
        if self.veracity: v_names.append('ver')
        
        # Unir con guiones y a√±adir extensi√≥n
        if v_names:
            return f"{'_'.join(v_names)}.png"
        else:
            return "demo.png"  # Fallback por si no hay ninguna V activada

    def _cleanup_data_folder(self):
        """Limpia la carpeta data despu√©s de generar la gr√°fica"""
        try:
            from pathlib import Path
            import shutil
            
            data_folder = Path("data")
            if data_folder.exists():
                # Contar archivos antes de limpiar
                files_before = list(data_folder.rglob("*"))
                file_count = len([f for f in files_before if f.is_file()])
                
                if file_count > 0:
                    shutil.rmtree(data_folder)
                    data_folder.mkdir(exist_ok=True)
                    print(f"üßπ Carpeta data limpiada ({file_count} archivos eliminados)")
                else:
                    print("üìÅ Carpeta data ya estaba vac√≠a")
            else:
                print("üìÅ Carpeta data no existe")
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Error limpiando carpeta data: {e}")

    def generate_performance_chart(self):
        """Genera gr√°fica de rendimiento al finalizar"""
        if not MATPLOTLIB_AVAILABLE:
            print("üìä Gr√°ficas no disponibles (matplotlib no instalado)")
            return
            
        if not self.performance_data['iterations']:
            print("‚ö†Ô∏è  No hay datos de rendimiento para generar gr√°fica")
            return
            
        print(f"üìä Generando gr√°fica con {len(self.performance_data['iterations'])} puntos de datos...")
        
        # Deshabilitar interrupciones durante TODO el proceso de generaci√≥n
        import signal
        import os
        old_handler = signal.signal(signal.SIGINT, signal.SIG_IGN)
        
        try:
            # Configurar el estilo de la gr√°fica
            try:
                plt.style.use('seaborn-v0_8')
            except:
                plt.style.use('seaborn')
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
            iterations = self.performance_data['iterations']
            times = self.performance_data['processing_times']
            numbers_in_file = self.performance_data['numbers_in_file']
            numbers_processed = self.performance_data['numbers_processed']
            total_processed = self.performance_data['total_numbers_processed']
            
            # Gr√°fica 1: Tiempo de procesamiento por iteraci√≥n
            ax1.plot(iterations, times, 'b-o', linewidth=2, markersize=4)
            ax1.set_title('Tiempo de Procesamiento por Iteraci√≥n', fontsize=14, fontweight='bold')
            ax1.set_xlabel('Iteraci√≥n')
            ax1.set_ylabel('Tiempo (ms)')
            ax1.grid(True, alpha=0.3)
            ax1.set_facecolor('#f8f9fa')
            
            # Gr√°fica 2: N√∫meros en archivo vs N√∫meros procesados
            ax2.plot(iterations, numbers_in_file, 'r-s', label='N√∫meros en Archivo', linewidth=2, markersize=4)
            ax2.plot(iterations, total_processed, 'g-^', label='Total Procesados', linewidth=2, markersize=4)
            ax2.set_title('Volumen: Archivo vs Procesados', fontsize=14, fontweight='bold')
            ax2.set_xlabel('Iteraci√≥n')
            ax2.set_ylabel('Cantidad de N√∫meros')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            ax2.set_facecolor('#f8f9fa')
            
            # Gr√°fica 3: Retraso (solo para velocity)
            if self.velocity:
                delay = [nf - tp for nf, tp in zip(numbers_in_file, total_processed)]
                ax3.plot(iterations, delay, 'orange', linewidth=3, marker='d', markersize=5)
                ax3.fill_between(iterations, delay, alpha=0.3, color='orange')
                ax3.set_title('Retraso Creciente (Velocity)', fontsize=14, fontweight='bold')
                ax3.set_xlabel('Iteraci√≥n')
                ax3.set_ylabel('N√∫meros de Retraso')
                ax3.grid(True, alpha=0.3)
                ax3.set_facecolor('#fff3cd')
            else:
                # Para volume: mostrar escalabilidad
                if len(times) > 1 and max(numbers_in_file) > min(numbers_in_file):
                    ax3.scatter(numbers_in_file, times, c=iterations, cmap='viridis', s=50, alpha=0.7)
                    ax3.set_title('Escalabilidad: Volumen vs Tiempo', fontsize=14, fontweight='bold')
                    ax3.set_xlabel('N√∫meros en Archivo')
                    ax3.set_ylabel('Tiempo de Procesamiento (ms)')
                    cbar = plt.colorbar(ax3.scatter(numbers_in_file, times, c=iterations, cmap='viridis', s=50, alpha=0.7), ax=ax3)
                    cbar.set_label('Iteraci√≥n')
                    ax3.grid(True, alpha=0.3)
                    ax3.set_facecolor('#e8f5e8')
                else:
                    ax3.text(0.5, 0.5, 'Datos insuficientes\npara an√°lisis de escalabilidad', 
                            ha='center', va='center', transform=ax3.transAxes, fontsize=12)
                    ax3.set_title('Escalabilidad: Volumen vs Tiempo', fontsize=14, fontweight='bold')
            
            # Gr√°fico 4: Veracity - Errores detectados
            ax4.bar(range(len(self.performance_data['veracity_errors'])), 
                   self.performance_data['veracity_errors'],
                   color='red', alpha=0.7)
            ax4.set_title("Veracity: Errores detectados por iteraci√≥n")
            ax4.set_xlabel("Iteraci√≥n")
            ax4.set_ylabel("N√∫mero de errores")
            
            plt.tight_layout()
            
            # Generar nombre de archivo basado en las Vs activadas
            filename = self._generate_chart_filename()
            filepath = os.path.join(self.output_folder, filename)
            
            plt.savefig(filepath, dpi=300, bbox_inches='tight')
            print(f"üìà Gr√°fica guardada como: {filename}")
            
            # Limpiar datos despu√©s de generar la gr√°fica
            self._cleanup_data_folder()
            
            # Configurar t√≠tulo general
            mode_names = []
            if self.velocity: mode_names.append('Velocity')
            if self.volume: mode_names.append('Volume')  
            if self.variety: mode_names.append('Variety')
            if self.veracity: mode_names.append('Veracity')
            
            title = f"An√°lisis de Rendimiento - {' + '.join(mode_names)}"
            fig.suptitle(title, fontsize=16, fontweight='bold')
            
        except Exception as e:
            print(f"‚ùå Error durante la generaci√≥n de gr√°fica: {e}")
        finally:
            # Restaurar el handler original de se√±ales SIEMPRE
            signal.signal(signal.SIGINT, old_handler)
            # Cerrar la figura para liberar memoria
            try:
                plt.close()
            except:
                pass
            
        print(f"‚úÖ Gr√°fica generada exitosamente")
        
        # Mostrar estad√≠sticas finales
        if self.performance_data['processing_times']:
            times = self.performance_data['processing_times']
            iterations = self.performance_data['iterations']
            numbers_in_file = self.performance_data['numbers_in_file']
            total_processed = self.performance_data['total_numbers_processed']
            
            print(f"\nüìà ESTAD√çSTICAS FINALES:")
            print(f"   Iteraciones totales: {len(iterations)}")
            print(f"   Tiempo promedio: {np.mean(times):.2f} ms")
            print(f"   Tiempo m√°ximo: {max(times):.2f} ms")
            print(f"   Tiempo m√≠nimo: {min(times):.2f} ms")
            if self.velocity and len(numbers_in_file) > 0 and len(total_processed) > 0:
                final_delay = numbers_in_file[-1] - total_processed[-1]
                print(f"   Retraso final: {final_delay} n√∫meros")
            if len(numbers_in_file) > 0:
                print(f"   Volumen m√°ximo: {max(numbers_in_file)} n√∫meros")

    def find_files_to_process(self):
        """Encuentra archivos existentes para procesar"""
        all_files = []
        
        if self.variety:
            # Buscar m√∫ltiples formatos con nombres fijos
            filenames = ['data.txt', 'data.csv', 'data.json']
            for filename in filenames:
                filepath = self.data_folder / filename
                if filepath.exists():
                    all_files.append(str(filepath))
        else:
            # Solo TXT por defecto
            filepath = self.data_folder / 'data.txt'
            if filepath.exists():
                all_files.append(str(filepath))
        
        return all_files

    def process_files(self):
        """Procesa todos los archivos disponibles"""
        start_time = time.time()
        
        files_to_process = self.find_files_to_process()
        
        if not files_to_process:
            return None
        
        # Para velocity: verificar si hay n√∫meros nuevos que procesar
        if self.velocity:
            # En velocity, verificamos si hay m√°s n√∫meros que los ya procesados
            for filepath in files_to_process:
                numbers = self.get_file_numbers(filepath)
                if len(numbers) > self.processed_count:
                    # Hay n√∫meros nuevos para procesar
                    break
            else:
                # No hay n√∫meros nuevos
                return None
        else:
            # Para otros modos: verificar cambios en tama√±o de archivos
            current_sizes = {}
            has_changes = False
            
            for filepath in files_to_process:
                try:
                    size = Path(filepath).stat().st_size
                    current_sizes[filepath] = size
                    if filepath not in self.last_file_sizes or self.last_file_sizes[filepath] != size:
                        has_changes = True
                except:
                    current_sizes[filepath] = 0
            
            # Si no hay cambios, no procesar
            if not has_changes and self.last_file_sizes:
                return None
            
            # Actualizar tama√±os
            self.last_file_sizes = current_sizes.copy()
        
        if self.variety and self.velocity:
            # Variety + Velocity: procesar un n√∫mero de cada formato
            results_by_type = defaultdict(lambda: {'sum': 0, 'count': 0, 'files': [], 'total_in_file': 0})
            
            has_new_numbers = False
            for filepath in files_to_process:
                # Para velocity: obtener solo el siguiente n√∫mero sin procesar
                new_numbers, total_in_file = self.get_next_number_for_velocity(filepath)
                file_type = Path(filepath).suffix
                
                if new_numbers:
                    has_new_numbers = True
                    file_sum = new_numbers[0]  # Solo el n√∫mero nuevo
                    results_by_type[file_type]['sum'] = file_sum
                    results_by_type[file_type]['count'] = 1
                    results_by_type[file_type]['files'] = [Path(filepath).name]
                    results_by_type[file_type]['total_in_file'] = total_in_file
            
            if not has_new_numbers:
                return None
            
            end_time = time.time()
            processing_time = (end_time - start_time) * 1000
            
            print(f"\n‚è±Ô∏è  Tiempo de procesamiento: {processing_time:.2f} ms")
            print(f"üìÅ Archivos procesados: {len(files_to_process)}")
            
            # Mostrar resultados por tipo
            total_in_all_files = 0
            for file_type, data in results_by_type.items():
                print(f"   {file_type}: N√∫mero procesado={data['sum']}, "
                      f"Total en archivo={data['total_in_file']}")
                total_in_all_files = max(total_in_all_files, data['total_in_file'])
            
            print(f"üî¢ N√∫mero procesado de cada formato")
            print(f"üìä Total procesados hasta ahora: {self.processed_count}")
            
            # Detectar discrepancias si veracity est√° activo
            errors_detected = 0
            if self.veracity and len(results_by_type) > 1:
                sums = [data['sum'] for data in results_by_type.values()]
                if len(set(sums)) > 1:
                    errors_detected = 1
                    print(f"‚ö†Ô∏è  DISCREPANCIA DETECTADA: Los n√∫meros no coinciden entre formatos")
            
            # Recopilar datos para gr√°fica (variety + velocity)
            if len(self.performance_data['iterations']) == 0:
                iteration = 0
            else:
                iteration = self.performance_data['iterations'][-1] + 1
            
            self.performance_data['iterations'].append(iteration)
            self.performance_data['processing_times'].append(processing_time)
            self.performance_data['numbers_in_file'].append(total_in_all_files)
            self.performance_data['numbers_processed'].append(1)  # Solo 1 por iteraci√≥n en velocity
            self.performance_data['total_numbers_processed'].append(self.processed_count)
            self.performance_data['veracity_errors'].append(errors_detected)
            
            return processing_time
            
        elif self.variety:
            # Variety sin velocity: procesar todos los n√∫meros
            results_by_type = defaultdict(lambda: {'sum': 0, 'count': 0, 'files': []})
            
            for filepath in files_to_process:
                numbers = self.get_file_numbers(filepath)
                if numbers:
                    file_sum = sum(numbers)
                    file_type = Path(filepath).suffix
                    
                    results_by_type[file_type]['sum'] = file_sum  # Cambio: asignar en lugar de sumar
                    results_by_type[file_type]['count'] = len(numbers)  # Total actual
                    results_by_type[file_type]['files'] = [Path(filepath).name]
            
            end_time = time.time()
            processing_time = (end_time - start_time) * 1000
            
            print(f"\n‚è±Ô∏è  Tiempo de procesamiento: {processing_time:.2f} ms")
            print(f"üìÅ Archivos procesados: {len(files_to_process)}")
            
            # Mostrar resultados por tipo
            total_numbers_variety = 0
            for file_type, data in results_by_type.items():
                print(f"   {file_type}: Suma={data['sum']}, "
                      f"N√∫meros={data['count']}, "
                      f"Archivos={len(data['files'])}")
                if data['count'] > total_numbers_variety:
                    total_numbers_variety = data['count']  # Usar el m√°ximo
            
            # Detectar discrepancias si veracity est√° activo
            errors_detected = 0
            if self.veracity and len(results_by_type) > 1:
                sums = [data['sum'] for data in results_by_type.values()]
                if len(set(sums)) > 1:
                    errors_detected = 1
                    print(f"‚ö†Ô∏è  DISCREPANCIA DETECTADA: Las sumas no coinciden entre formatos")
            
            # Recopilar datos para gr√°fica (variety/veracity)
            if len(self.performance_data['iterations']) == 0:
                iteration = 0
            else:
                iteration = self.performance_data['iterations'][-1] + 1
            
            self.performance_data['iterations'].append(iteration)
            self.performance_data['processing_times'].append(processing_time)
            self.performance_data['numbers_in_file'].append(total_numbers_variety)
            self.performance_data['numbers_processed'].append(total_numbers_variety)
            self.performance_data['total_numbers_processed'].append(total_numbers_variety)
            self.performance_data['veracity_errors'].append(errors_detected)
            
            return processing_time
            
        elif self.velocity:
            # Velocity sin variety: procesar solo UN n√∫mero nuevo por vez
            for filepath in files_to_process:
                new_numbers, total_in_file = self.get_next_number_for_velocity(filepath)
                
                if new_numbers:
                    end_time = time.time()
                    processing_time = (end_time - start_time) * 1000
                    
                    number_processed = new_numbers[0]
                    print(f"\n‚è±Ô∏è  Tiempo de procesamiento: {processing_time:.2f} ms")
                    print(f"üìÑ {Path(filepath).name}: {total_in_file} n√∫meros en el archivo")
                    print(f"üî¢ N√∫mero procesado: {number_processed}")
                    print(f"üìä Total procesados hasta ahora: {self.processed_count}")
                    
                    # Recopilar datos para gr√°fica (solo en velocity)
                    if len(self.performance_data['iterations']) == 0:
                        iteration = 0
                    else:
                        iteration = self.performance_data['iterations'][-1] + 1
                    
                    self.performance_data['iterations'].append(iteration)
                    self.performance_data['processing_times'].append(processing_time)
                    self.performance_data['numbers_in_file'].append(total_in_file)
                    self.performance_data['numbers_processed'].append(1)  # Siempre 1 en velocity
                    self.performance_data['total_numbers_processed'].append(self.processed_count)
                    self.performance_data['veracity_errors'].append(0)  # No hay errores en velocity puro
                    
                    return processing_time
            
            # No hay n√∫meros nuevos
            return None
            
        else:
            # Volume u otros: procesar todos los n√∫meros
            total_sum = 0
            total_numbers = 0
            
            for filepath in files_to_process:
                numbers = self.get_file_numbers(filepath)
                if numbers:
                    total_sum = sum(numbers)  # Total actual en el archivo
                    total_numbers = len(numbers)  # Cantidad actual
            
            end_time = time.time()
            processing_time = (end_time - start_time) * 1000
            
            print(f"\n‚è±Ô∏è  Tiempo de procesamiento: {processing_time:.2f} ms")
            print(f"üìÅ Archivos procesados: {len(files_to_process)}")
            print(f"üî¢ Suma total: {total_sum}")
            print(f"üìä N√∫meros totales procesados: {total_numbers}")
            
            # Recopilar datos para gr√°fica (volume, etc)
            if len(self.performance_data['iterations']) == 0:
                iteration = 0
            else:
                iteration = self.performance_data['iterations'][-1] + 1
            
            self.performance_data['iterations'].append(iteration)
            self.performance_data['processing_times'].append(processing_time)
            self.performance_data['numbers_in_file'].append(total_numbers)
            self.performance_data['numbers_processed'].append(total_numbers)
            self.performance_data['total_numbers_processed'].append(total_numbers)
            self.performance_data['veracity_errors'].append(0)  # No hay errores en volume puro
            
            return processing_time

    def run(self):
        """Ejecuta el consumer continuamente"""
        print("üîç Consumer iniciado...")
        print(f"   Velocity: {self.velocity}")
        print(f"   Volume: {self.volume}")
        print(f"   Variety: {self.variety}")
        print(f"   Veracity: {self.veracity}")
        print("-" * 50)
        
        iteration = 0
        
        try:
            while True:
                print(f"\nüìã Iteraci√≥n {iteration}:")
                
                processing_time = self.process_files()
                
                if processing_time is None:
                    print("   ‚è≥ No hay archivos nuevos para procesar...")
                
                time.sleep(1)  # Intervalo de lectura
                iteration += 1
                
        except KeyboardInterrupt:
            print(f"\nüõë Consumer detenido despu√©s de {iteration} iteraciones")
            
            # Generar gr√°fica de rendimiento
            print("\nüìä Generando gr√°fica de rendimiento...")
            try:
                self.generate_performance_chart()
            except Exception as e:
                print(f"‚ö†Ô∏è  Error generando gr√°fica: {e}")
                print("Aseg√∫rate de tener matplotlib instalado: pip install matplotlib")

def main():
    parser = argparse.ArgumentParser(description="Consumer para Big Data")
    parser.add_argument("--velocity", type=str, default="false")
    parser.add_argument("--volume", type=str, default="false")
    parser.add_argument("--variety", type=str, default="false")
    parser.add_argument("--veracity", type=str, default="false")
    
    args = parser.parse_args()
    
    # Convertir a booleans
    velocity = args.velocity.lower() == "true"
    volume = args.volume.lower() == "true"
    variety = args.variety.lower() == "true"
    veracity = args.veracity.lower() == "true"
    
    consumer = BigDataConsumer(velocity, volume, variety, veracity)
    consumer.run()

if __name__ == "__main__":
    main()
